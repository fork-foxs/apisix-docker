#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

version: "3.8"

configs:
  apisix_config:
    file: ./apisix_conf/config.yaml
  dashboard_config:
    file: ./dashboard_conf/config.yaml
  prometheus_config:
    file: ./prometheus_conf/prometheus.yml
  grafana_config:
    file: ./grafana_conf/config/grafana.ini
  grafana_datasources:
    file: ./grafana_conf/provisioning/datasources/all.yaml
  grafana_dashboards:
    file: ./grafana_conf/provisioning/dashboards/all.yaml
  grafana_dashboard_json:
    file: ./grafana_conf/dashboards/apisix-grafana-dashboard.json
  web1_config:
    file: ./upstream/web1.conf
  web2_config:
    file: ./upstream/web2.conf

services:
  apisix:
    image: apache/apisix:${APISIX_IMAGE_TAG:-3.14.1-debian}
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '16'
          memory: 32G
        reservations:
          cpus: '8'
          memory: 16G
      placement:
        constraints:
          - node.role == worker
    configs:
      - source: apisix_config
        target: /usr/local/apisix/conf/config.yaml
        mode: 0444
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/v1/schema"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    ports:
      - "9180:9180/tcp"
      - "9080:9080/tcp"
      - "9091:9091/tcp"
      - "9443:9443/tcp"
      - "9092:9092/tcp"
    networks:
      - apisix

  etcd:
    image: bitnamilegacy/etcd:3.5.11
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      placement:
        constraints:
          - node.role == worker
    volumes:
      - etcd_data:/bitnami/etcd
    environment:
      ETCD_ENABLE_V2: "true"
      ALLOW_NONE_AUTHENTICATION: "yes"
      ETCD_ADVERTISE_CLIENT_URLS: "http://etcd:2379"
      ETCD_LISTEN_CLIENT_URLS: "http://0.0.0.0:2379"
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    ports:
      - "2379:2379/tcp"
    networks:
      - apisix

  web1:
    image: nginx:1.19.0-alpine
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
      placement:
        constraints:
          - node.role == worker
    configs:
      - source: web1_config
        target: /etc/nginx/nginx.conf
        mode: 0444
    ports:
      - "9081:80/tcp"
    environment:
      - NGINX_PORT=80
    networks:
      - apisix

  web2:
    image: nginx:1.19.0-alpine
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
      placement:
        constraints:
          - node.role == worker
    configs:
      - source: web2_config
        target: /etc/nginx/nginx.conf
        mode: 0444
    ports:
      - "9082:80/tcp"
    environment:
      - NGINX_PORT=80
    networks:
      - apisix

  prometheus:
    image: prom/prometheus:v2.25.0
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      placement:
        constraints:
          - node.role == worker
    configs:
      - source: prometheus_config
        target: /etc/prometheus/prometheus.yml
        mode: 0444
    ports:
      - "9090:9090"
    networks:
      - apisix

  grafana:
    image: grafana/grafana:7.3.7
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      placement:
        constraints:
          - node.role == worker
    ports:
      - "3002:3000"
    configs:
      - source: grafana_config
        target: /etc/grafana/grafana.ini
        mode: 0444
      - source: grafana_datasources
        target: /etc/grafana/provisioning/datasources/all.yaml
        mode: 0444
      - source: grafana_dashboards
        target: /etc/grafana/provisioning/dashboards/all.yaml
        mode: 0444
      - source: grafana_dashboard_json
        target: /var/lib/grafana/dashboards/apisix-grafana-dashboard.json
        mode: 0444
    networks:
      - apisix

  dashboard:
    image: harbor.fintechsys.net/api-gateway-six/apisix-dashboard:latest
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '16'
          memory: 32G
        reservations:
          cpus: '4'
          memory: 8G
      placement:
        constraints:
          - node.role == worker
    configs:
      - source: dashboard_config
        target: /usr/local/apisix-dashboard/conf/conf.yaml
        mode: 0444
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    ports:
      - "9000:9000/tcp"
    networks:
      - apisix

networks:
  apisix:
    driver: overlay
    attachable: true

volumes:
  etcd_data:
    driver: local